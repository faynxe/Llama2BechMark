# Llama2BechMark

Python Notebooks that walk you through how to deploy various LLama2 and LLama Code models to a SageMaker realtime endpoint using the HuggingFace TGI inference image and do some benchmarking.

For BenchMarking of LLama2 Text Generation Models, see the **LLAMA2-BenchMark** notebook
For BenchMarking of Code LLama Text Generation Models, see the **LLAMA-CODE BenchMARK** notebook
To deploy a quantized version of LLama2 Text Generation Models, see the **LLama2-GPTQ** notebook
